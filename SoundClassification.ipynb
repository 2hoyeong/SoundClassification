{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SoundClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2hoyeong/SoundClassification/blob/master/SoundClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCDudSvpTww-",
        "colab_type": "code",
        "outputId": "dd9c0b42-302e-4934-d7cd-911d59b32f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Google drive 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4txmzAUUgXj",
        "colab_type": "code",
        "outputId": "8f3abba2-0435-4a86-e673-119af635f06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Mon Dec 16 01:34:24 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-l_dtZ0WhPb",
        "colab_type": "code",
        "outputId": "4e6d2247-1144-4aeb-ed2b-c8f09a00ae97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!pip install numpy scipy\n",
        "!pip install resampy six\n",
        "!pip install pysoundfile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.3.3)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.13 in /usr/local/lib/python3.6/dist-packages (from resampy) (1.3.3)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy) (0.40.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from resampy) (1.17.4)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy) (0.30.0)\n",
            "Requirement already satisfied: pysoundfile in /usr/local/lib/python3.6/dist-packages (0.9.0.post1)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.6/dist-packages (from pysoundfile) (1.13.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=0.6->pysoundfile) (2.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ahEiwJvWxCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Architectural constants.\n",
        "#NUM_FRAMES = 96  # Frames in input mel-spectrogram patch.\n",
        "#NUM_BANDS = 64  # Frequency bands in input mel-spectrogram patch.\n",
        "NUM_FRAMES = 40\n",
        "NUM_BANDS = 313\n",
        "EMBEDDING_SIZE = 128  # Size of embedding layer.\n",
        "\n",
        "# Hyperparameters used in feature and example generation.\n",
        "SAMPLE_RATE = 16000\n",
        "STFT_WINDOW_LENGTH_SECONDS = 0.025\n",
        "STFT_HOP_LENGTH_SECONDS = 0.010\n",
        "NUM_MEL_BINS = NUM_BANDS\n",
        "MEL_MIN_HZ = 125\n",
        "MEL_MAX_HZ = 7500\n",
        "LOG_OFFSET = 0.001  # Offset used for stabilized log of input mel-spectrogram.\n",
        "EXAMPLE_WINDOW_SECONDS = 0.96  # Each example contains 96 10ms frames\n",
        "EXAMPLE_HOP_SECONDS = 0.48     # with zero overlap.\n",
        "\n",
        "# Parameters used for embedding postprocessing.\n",
        "PCA_EIGEN_VECTORS_NAME = 'pca_eigen_vectors'\n",
        "PCA_MEANS_NAME = 'pca_means'\n",
        "QUANTIZE_MIN_VAL = -2.0\n",
        "QUANTIZE_MAX_VAL = +2.0\n",
        "\n",
        "# Hyperparameters used in training.\n",
        "INIT_STDDEV = 0.01  # Standard deviation used to initialize weights.\n",
        "LEARNING_RATE = 1e-4  # Learning rate for the Adam optimizer.\n",
        "ADAM_EPSILON = 1e-8  # Epsilon for the Adam optimizer.\n",
        "\n",
        "# Names of ops, tensors, and features.\n",
        "INPUT_OP_NAME = 'vggish/input_features'\n",
        "INPUT_TENSOR_NAME = INPUT_OP_NAME + ':0'\n",
        "OUTPUT_OP_NAME = 'embedding'\n",
        "OUTPUT_TENSOR_NAME = OUTPUT_OP_NAME + ':0'\n",
        "AUDIO_EMBEDDING_FEATURE_NAME = 'audio_embedding'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vTXlxY_XCgz",
        "colab_type": "code",
        "outputId": "423fab3e-0d50-4412-e02b-f8a2fb22a41a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import random\n",
        "import librosa\n",
        "slim = tf.contrib.slim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yexJ7nrVXGi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_vggish_slim(training=False):\n",
        "  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
        "                      weights_initializer=tf.truncated_normal_initializer(\n",
        "                          stddev=INIT_STDDEV),\n",
        "                      biases_initializer=tf.zeros_initializer(),\n",
        "                      activation_fn=tf.nn.relu,\n",
        "                      trainable=training), \\\n",
        "       slim.arg_scope([slim.conv2d],\n",
        "                      kernel_size=[3, 3], stride=1, padding='SAME'), \\\n",
        "       slim.arg_scope([slim.max_pool2d],\n",
        "                      kernel_size=[2, 2], stride=2, padding='SAME'), \\\n",
        "       tf.variable_scope('vggish'):\n",
        "    # Input: a batch of 2-D log-mel-spectrogram patches.\n",
        "    features = tf.placeholder(\n",
        "        tf.float32, shape=(None, NUM_FRAMES, NUM_BANDS),\n",
        "        name='input_features')\n",
        "    # Reshape to 4-D so that we can convolve a batch with conv2d().\n",
        "    net = tf.reshape(features, [-1, NUM_FRAMES, NUM_BANDS, 1])\n",
        "\n",
        "    # The VGG stack of alternating convolutions and max-pools.\n",
        "    net = slim.conv2d(net, 64, scope='conv1')\n",
        "    net = slim.max_pool2d(net, scope='pool1')\n",
        "    net = slim.conv2d(net, 128, scope='conv2')\n",
        "    net = slim.max_pool2d(net, scope='pool2')\n",
        "    net = slim.repeat(net, 2, slim.conv2d, 256, scope='conv3')\n",
        "    net = slim.max_pool2d(net, scope='pool3')\n",
        "    net = slim.repeat(net, 2, slim.conv2d, 512, scope='conv4')\n",
        "    net = slim.max_pool2d(net, scope='pool4')\n",
        "\n",
        "    # Flatten before entering fully-connected layers\n",
        "    net = slim.flatten(net)\n",
        "    net = slim.repeat(net, 2, slim.fully_connected, 4096, scope='fc1')\n",
        "    # The embedding layer.\n",
        "    net = slim.fully_connected(net, EMBEDDING_SIZE, scope='fc2')\n",
        "    return tf.identity(net, name='embedding')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNs8yqRw_ZPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(audio, sr):\n",
        "  try:\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Error encountered while parsing file: \", audio)\n",
        "    return None \n",
        "  return mfccs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7ZuDLhhXIKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCH = 2000\n",
        "_NUM_CLASSES = 3\n",
        "\n",
        "sr = 16000\n",
        "sampling_r = 16000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ0GcSuaXKNU",
        "colab_type": "code",
        "outputId": "9e4de08a-bc3f-4fc0-858f-65c10002374d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "embeddings = define_vggish_slim(True)\n",
        "\n",
        "num_units = 128\n",
        "fc = slim.fully_connected(embeddings, num_units)\n",
        "\n",
        "logits = slim.fully_connected(\n",
        "    fc, _NUM_CLASSES, activation_fn=None, scope='logits')\n",
        "\n",
        "predict = tf.sigmoid(logits, name='prediction')\n",
        "\n",
        "# Add training ops.\n",
        "global_step = tf.Variable(\n",
        "    0, name='global_step', trainable=False,\n",
        "    collections=[tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                    tf.GraphKeys.GLOBAL_STEP])\n",
        "\n",
        "# Labels are assumed to be fed as a batch multi-hot vectors, with\n",
        "# a 1 in the position of each positive class label, and 0 elsewhere.\n",
        "labels = tf.placeholder(\n",
        "    tf.float32, shape=(None, _NUM_CLASSES), name='labels')\n",
        "\n",
        "# Cross-entropy label loss.\n",
        "xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "    logits=logits, labels=labels, name='xent')\n",
        "loss = tf.reduce_mean(xent, name='loss_op')\n",
        "loss_summary = tf.summary.scalar('loss', loss)\n",
        "\n",
        "# We use the same optimizer and hyperparameters as used to train VGGish.\n",
        "optimizer = tf.train.AdamOptimizer(\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    epsilon=ADAM_EPSILON)\n",
        "optimizer.minimize(loss, global_step=global_step, name='train_op')\n",
        "\n",
        "# Initialize all variables in the model, and then load the pre-trained\n",
        "# VGGish checkpoint.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "#vggish_slim.load_vggish_slim_checkpoint(sess, 'vggish_model.ckpt')\n",
        "\n",
        "# Locate all the tensors and ops we need for the training loop.\n",
        "features_tensor = sess.graph.get_tensor_by_name(INPUT_TENSOR_NAME)\n",
        "labels_tensor = sess.graph.get_tensor_by_name('labels:0')\n",
        "global_step_tensor = sess.graph.get_tensor_by_name(\n",
        "'global_step:0')\n",
        "\n",
        "loss_tensor = sess.graph.get_tensor_by_name('loss_op:0')\n",
        "train_op = sess.graph.get_operation_by_name('train_op')\n",
        "\n",
        "correct_predictions = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "accuracy_tensor = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
        "accuracy_summary = tf.summary.scalar('accuracy', accuracy_tensor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix-EBY_vXNkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_LABEL_CLASSES = ['car', 'siren', 'shout']\n",
        "data_dir = '/content/gdrive/My Drive/colab/data/SoundClassification'\n",
        "exportdir = \"/content/gdrive/My Drive/colab/code/vggish\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaBH9-6KKp50",
        "colab_type": "code",
        "outputId": "4e847cf3-69c0-4663-cfab-ce35be290b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "total_parameters = 0\n",
        "for variable in tf.trainable_variables():\n",
        "    # shape is an array of tf.Dimension\n",
        "    shape = variable.get_shape()\n",
        "    variable_parameters = 1\n",
        "    for dim in shape:\n",
        "        variable_parameters *= dim.value\n",
        "    total_parameters += variable_parameters\n",
        "print(total_parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "147655555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t4EIW9iXO6g",
        "colab_type": "code",
        "outputId": "bb127595-00e7-4e1b-84ba-5728f52cf5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "TRAIN_NUM_BATCH = 200\n",
        "EVAL_NUM_BATCH = 20\n",
        "acc_for_graph = [0]\n",
        "saver = tf.train.Saver()\n",
        "try:\n",
        "  for steps in range(1, NUM_EPOCH + 1):\n",
        "      for CLASS in range(len(_LABEL_CLASSES)):\n",
        "          all_files = [data_dir + '/train/' + _LABEL_CLASSES[CLASS] + '/' + f for f in listdir(data_dir + '/train/' + _LABEL_CLASSES[CLASS] + '/') if isfile(join(data_dir + '/train/' + _LABEL_CLASSES[CLASS] + '/', f))]\n",
        "          files = random.sample(all_files, TRAIN_NUM_BATCH)\n",
        "          y, sr = librosa.load(files[0], sr=sampling_r)\n",
        "          feature = [extract_features(y, sr)]\n",
        "          for file in files[1:]:\n",
        "            y, sr = librosa.load(file, sr=sampling_r)\n",
        "            bytes = [extract_features(y, sr)]\n",
        "            feature = np.concatenate((feature, bytes))\n",
        "\n",
        "          label = np.array([[int(i == CLASS) for i in range(3)]] * feature.shape[0])\n",
        "          [num_steps, loss, _, acc, predction] = sess.run(\n",
        "                [global_step_tensor, loss_tensor, train_op, accuracy_tensor, predict], feed_dict={features_tensor:feature, labels_tensor: label})\n",
        "          \n",
        "          print(\"[{:d} steps Training] loss {:g}, acc {:g}%\".format(steps, loss, (acc * 100)))\n",
        "          if steps % 10 == 0:\n",
        "            print(np.shape(predction), predction[0])\n",
        "      if steps % 5 == 0:\n",
        "        for i in range(len(_LABEL_CLASSES)):\n",
        "          eval_files = [data_dir + '/eval/' + _LABEL_CLASSES[i] + '/' + f for f in listdir(data_dir + '/eval/' + _LABEL_CLASSES[i] + '/') if isfile(join(data_dir + '/eval/' + _LABEL_CLASSES[i] + '/', f))]\n",
        "          random.shuffle(eval_files)\n",
        "          y, sr = librosa.load(eval_files[0], sr=sampling_r)\n",
        "          feature = [extract_features(y, sr)]\n",
        "          for file in eval_files[1:]:\n",
        "            y, sr = librosa.load(file, sr=sampling_r)\n",
        "            bytes = [extract_features(y, sr)]\n",
        "            feature = np.concatenate((feature, bytes))\n",
        "          label = np.array([[int(a == i) for a in range(3)]] * feature.shape[0])\n",
        "          [num_steps, loss, _, acc, predction] = sess.run(\n",
        "                  [global_step_tensor, loss_tensor, train_op, accuracy_tensor, predict],\n",
        "                  feed_dict={features_tensor: feature, labels_tensor: label})\n",
        "\n",
        "          print(\"[{:d} steps {:s} Evaluation] loss {:g}, acc {:g}%\".format(i, _LABEL_CLASSES[i], loss, (acc * 100)))\n",
        "        ckpt_path = saver.save(sess, exportdir + \"/trained\")\n",
        "        print(\"SAVED :\", ckpt_path)\n",
        "except KeyboardInterrupt:\n",
        "  print(\"EXIT\")\n",
        "\n",
        "#tf.train.Saver().save(sess, exportdir + '/trained.ckpt')\n",
        "#tf.train.write_graph(sess.graph_def, \".\", exportdir + '/trained.pb', as_text=False)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_session(sess, [features_tensor], [predict])\n",
        "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = converter.convert()\n",
        "open(exportdir + \"/new_converted_model.tflite\", \"wb\").write(tflite_model)\n",
        "ckpt_path = saver.save(sess, exportdir + \"/trained\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 steps Training] loss 0.693125, acc 100%\n",
            "[1 steps Training] loss 0.693511, acc 0%\n",
            "[1 steps Training] loss 0.694585, acc 0%\n",
            "[0 steps car Evaluation] loss 0.692378, acc 100%\n",
            "[1 steps siren Evaluation] loss 0.692786, acc 0%\n",
            "[2 steps shout Evaluation] loss 0.693231, acc 0%\n",
            "SAVED : /content/gdrive/My Drive/colab/code/vggish/trained\n",
            "[2 steps Training] loss 0.690671, acc 100%\n",
            "[2 steps Training] loss 0.690983, acc 0%\n",
            "[2 steps Training] loss 0.692566, acc 0%\n",
            "EXIT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 22 variables.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-12-56df8ed5f575>\", line 48, in <module>\n",
            "    converter = tf.lite.TFLiteConverter.from_session(sess, [features_tensor], [predict])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py\", line 628, in from_session\n",
            "    graph_def = _freeze_graph(sess, input_tensors, output_tensors)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/util.py\", line 249, in freeze_graph\n",
            "    output_arrays)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py\", line 344, in convert_variables_to_constants\n",
            "    data, data.shape)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py\", line 272, in create_const_op\n",
            "    data, dtype=dtype.type, shape=data_shape)))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_util.py\", line 521, in make_tensor_proto\n",
            "    tensor_proto.tensor_content = nparray.tostring()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 739, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"/usr/lib/python3.6/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T5gsSNfNH_2c",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(acc_for_graph)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}